<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>リアルタイムカード枠検出とOCR（ボタンで実行）</title>
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();"></script>
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@4.0.2/dist/tesseract.min.js"></script>
  <style>
    video { display: none; }
    canvas { border: 1px solid black; display: block; margin: 10px auto; }
    #recognized-text { font-size: 16px; font-weight: bold; text-align: center; margin-top: 20px; }
    #ocr-button, #toggle-redline-button { display: block; margin: 30px auto; padding: 20px 40px; font-size: 24px; }
  </style>
</head>
<body>
  <h1>リアルタイムカード枠検出とOCR（ボタンで実行）</h1>
  <div id="opencv-status" style="font-weight: bold; margin: 1em;"></div>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvasOutput"></canvas>
  <button id="toggle-redline-button">赤線モード切り替え</button>
  <button id="ocr-button">OCRを実行</button>
  <div id="recognized-text">読み取った文字列: <span id="text-output">なし</span></div>

  <script>
    let video = document.getElementById('video');
    let canvas = document.getElementById('canvasOutput');
    let ctx = canvas.getContext('2d');
    let streaming = false;
    let textOutput = document.getElementById('text-output');
    let ocrButton = document.getElementById('ocr-button');
    let toggleRedLineButton = document.getElementById('toggle-redline-button');
    let redLineMode = 0; // 0: 通常, 1: 赤線表示, 2: 赤線のみ
    let lastFrameTime = 0; // フレームレート制限用

    toggleRedLineButton.addEventListener("click", () => {
      redLineMode = (redLineMode + 1) % 3;
      const modes = ["通常表示", "赤線表示", "赤線のみ"];
      toggleRedLineButton.innerText = `${modes[redLineMode]}モード`;
    });

    function onOpenCvReady() {
      const statusEl = document.getElementById("opencv-status");
      statusEl.innerText = "🔄 OpenCV.js 初期化中...";
      cv['onRuntimeInitialized'] = () => {
        statusEl.innerText = "✅ OpenCV.js 読み込み完了！";
        startCamera();
      };
    }

    function startCamera() {
      navigator.mediaDevices.getUserMedia({
        video: { facingMode: "environment" }
      }).then(stream => {
        video.srcObject = stream;
        video.play();
        streaming = true;
        video.addEventListener('loadedmetadata', () => {
          canvas.width = video.videoWidth / 2; // 解像度を半分に
          canvas.height = video.videoHeight / 2;
          processVideo();
        });
      }).catch(err => {
        console.error("カメラの起動に失敗しました: ", err);
        alert("カメラの起動に失敗しました。デバイスのカメラ権限を確認してください。");
      });
    }

    function processVideo() {
      const now = performance.now();
      if (now - lastFrameTime < 33) { // 約30fpsに制限
        requestAnimationFrame(processVideo);
        return;
      }
      lastFrameTime = now;

      if (!streaming) return;

      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      let src = cv.imread(canvas);
      let gray = new cv.Mat();
      let blurred = new cv.Mat();
      let edges = new cv.Mat();

      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0);
      cv.Canny(blurred, edges, 50, 150);

      let contours = new cv.MatVector();
      let hierarchy = new cv.Mat();
      cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

      if (redLineMode !== 0) {
        let maxArea = 0;
        let maxContour = null;
        for (let i = 0; i < contours.size(); ++i) {
          let cnt = contours.get(i);
          let area = cv.contourArea(cnt);
          if (area > maxArea) {
            maxArea = area;
            maxContour = cnt;
          }
        }

        if (maxContour) {
          let contoursColor = new cv.Scalar(255, 0, 0, 255); // 赤色
          if (redLineMode === 1) {
            cv.drawContours(src, contours, -1, contoursColor, 2);
          } else if (redLineMode === 2) {
            src = new cv.Mat.zeros(src.rows, src.cols, src.type());
            cv.drawContours(src, contours, -1, contoursColor, 2);
          }
        }
      }

      cv.imshow('canvasOutput', src);
      src.delete(); gray.delete(); blurred.delete(); edges.delete();
      contours.delete(); hierarchy.delete();

      if (streaming) requestAnimationFrame(processVideo);
    }

    ocrButton.addEventListener('click', () => {
      Tesseract.recognize(canvas, 'jpn', {
        logger: info => console.log(info)
      }).then(({ data: { text } }) => {
        textOutput.innerText = text.trim() || "なし";
      }).catch(err => {
        console.error("OCRエラー: ", err);
        textOutput.innerText = "エラー";
      });
    });
  </script>
</body>
</html>