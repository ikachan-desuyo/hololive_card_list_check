<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>リアルタイムカード枠検出（改善案切り替え版）</title>
  <style>
    video { display: none; }
    canvas { 
      border: 1px solid black; 
      display: block; 
      margin: 10px auto; 
    }
    button { display: inline-block; margin: 5px; padding: 10px 20px; font-size: 16px; }
    button.active { background: #4CAF50; color: white; }
    #opencv-status { font-weight: bold; margin: 10px; }
  </style>
  <!-- deferで呼ぶと関数定義後にロード -->
  <script defer src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady()"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/tesseract.js@4.0.2/dist/tesseract.min.js"></script>
</head>
<body>
  <h1>リアルタイムカード枠検出（改善案切り替え版）</h1>
  <div id="opencv-status">🔄 OpenCVロード中...</div>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvasOutput"></canvas>
  <div>
    <button id="mode1-button" class="active">改善案1</button>
    <button id="mode2-button">改善案2</button>
    <button id="mode3-button">改善案3</button>
  </div>
  <div>
    <button id="trim-button">トリミング</button>
    <button id="ocr-button">OCRを実行</button>
  </div>
  <div id="recognized-text">読み取った文字列: <span id="text-output">なし</span></div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvasOutput');
    const statusEl = document.getElementById('opencv-status');
    const textOutput = document.getElementById('text-output');
    const trimBtn = document.getElementById('trim-button');
    const ocrBtn = document.getElementById('ocr-button');
    let currentMode = 1;
    let streaming = false;

    // モード切り替えボタン
    ['mode1','mode2','mode3'].forEach((id, idx) => {
      document.getElementById(`${id}-button`)
        .addEventListener('click', () => setMode(idx+1));
    });

    function setMode(m) {
      currentMode = m;
      ['mode1','mode2','mode3'].forEach((id, idx) => {
        document.getElementById(`${id}-button`)
          .classList.toggle('active', currentMode === idx+1);
      });
      statusEl.innerText = `🔄 改善案${m} 適用中...`;
    }

    function onOpenCvReady() {
      statusEl.innerText = '✅ OpenCV読み込み完了';
      startCamera();
    }

    function startCamera() {
      navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } })
        .then(stream => {
          video.srcObject = stream;
          video.onloadedmetadata = () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            streaming = true;
            initCv();
          };
        })
        .catch(err => {
          console.error(err);
          alert('カメラ起動失敗');
        });
    }

    // OpenCV Mat変数（再利用）
    let cap, src, dst, gray, blurred, edges, hsv, mask, kernel, contours, hierarchy;

    function initCv() {
      cap = new cv.VideoCapture(video);
      src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
      dst = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
      gray = new cv.Mat(); blurred = new cv.Mat(); edges = new cv.Mat();
      hsv = new cv.Mat(); mask = new cv.Mat();
      kernel = cv.Mat.ones(5,5,cv.CV_8U);
      contours = new cv.MatVector(); hierarchy = new cv.Mat();
      requestAnimationFrame(processVideo);
    }

    function processVideo() {
      if (!streaming) return;
      cap.read(src);
      src.copyTo(dst);

      switch(currentMode) {
        case 1: mode1(); break;
        case 2: mode2(); break;
        case 3: mode3(); break;
      }

      cv.imshow(canvas, dst);
      requestAnimationFrame(processVideo);
    }

    function mode1() {
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
      cv.Canny(gray, edges, 50, 150);
      drawContours(edges);
    }

    function mode2() {
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
      cv.GaussianBlur(gray, blurred, new cv.Size(5,5), 0);
      cv.dilate(blurred, blurred, kernel);
      cv.erode(blurred, blurred, kernel);
      cv.Canny(blurred, edges, 50, 150);
      drawContours(edges);
    }

    function mode3() {
      cv.cvtColor(src, hsv, cv.COLOR_RGBA2HSV);
      cv.inRange(hsv, new cv.Scalar(0,50,50), new cv.Scalar(10,255,255), mask);
      drawContours(mask);
    }

    function drawContours(binMat) {
      cv.findContours(binMat, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
      for (let i = 0; i < contours.size(); i++) {
        let rect = cv.boundingRect(contours.get(i));
        cv.rectangle(dst, new cv.Point(rect.x,rect.y), new cv.Point(rect.x+rect.width, rect.y+rect.height), [255,0,0,255], 2);
      }
    }

    trimBtn.addEventListener('click', () => {
      statusEl.innerText = '✂️ トリミング実行中...';
      // トリミング処理の実装はここに
      statusEl.innerText = '✅ トリミング完了';
    });

    ocrBtn.addEventListener('click', () => {
      statusEl.innerText = '🔤 OCR実行中...';
      // OCR処理の実装はここに
      statusEl.innerText = '✅ OCR完了';
    });
  </script>
</body>
</html>